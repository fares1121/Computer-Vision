{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOkITaX3XyUd"
      },
      "source": [
        "# **ImageNet Dataset Images Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiILMUhaX5RD"
      },
      "source": [
        "The ImageNet dataset consists of 14 millions decent resolution (224 x 244 pixels each) images. The processing of this dataset requires a great amount of computing power in terms of CPU, GPU, and RAM. So, it is not suitable for everyday laptop. To provide more practice oppotunities for researchers and students, we will be using the Fast.ai's Imagenette Dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2hvxW5AlfsV"
      },
      "source": [
        "# Fast.ai's Imagenette Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wor-dWr9lknv"
      },
      "source": [
        "Imagenette is a dataset that's extracted from the large ImageNet collection of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbochGSEvBDm",
        "outputId": "9335b232-a1e2-4669-8353-d5299d80f8eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-22 23:20:54--  https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.173.32, 52.216.217.144, 52.217.199.128, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.173.32|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1557161267 (1.5G) [application/x-tar]\n",
            "Saving to: ‘imagenette2.tgz’\n",
            "\n",
            "imagenette2.tgz     100%[===================>]   1.45G  35.0MB/s    in 42s     \n",
            "\n",
            "2023-12-22 23:21:36 (35.6 MB/s) - ‘imagenette2.tgz’ saved [1557161267/1557161267]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf imagenette2.tgz"
      ],
      "metadata": {
        "id": "XLKk-57LxLpu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jg-xgbhl2Pm"
      },
      "source": [
        "**Load Images From Imagenette**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0Z_pfbPtVJp"
      },
      "source": [
        "Use Keras ImageDataGenerator to load the large images from the Imagenette dataset without maxing out the RAM."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "imagegen = ImageDataGenerator()\n",
        "train = imagegen.flow_from_directory(\"imagenette2/train/\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))\n",
        "val = imagegen.flow_from_directory(\"imagenette2/val/\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqFCsJ7pxZmV",
        "outputId": "d70b2f11-5123-42c4-98f6-0145e6065c53"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9469 images belonging to 10 classes.\n",
            "Found 3925 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG16 CNN Model Using Keras"
      ],
      "metadata": {
        "id": "nKrVXumdxhk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG16 is a CNN architecture containing 16 layers in total, with 13 convolutional layers."
      ],
      "metadata": {
        "id": "fYvebl6Fxt8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download VGG16 Weights**"
      ],
      "metadata": {
        "id": "YcjDVQpXyHxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "# include top should be False to remove the softmax layer\n",
        "pretrained_model = VGG16(include_top=False, weights='imagenet')\n",
        "pretrained_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIL2cLFlyMl5",
        "outputId": "189d2651-f351-467b-d4aa-1944aa7f3db4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 14714688 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Features From VGG16**"
      ],
      "metadata": {
        "id": "IymEUhkBybTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "# extract train and val features\n",
        "vgg_features_train = pretrained_model.predict(train)\n",
        "vgg_features_val = pretrained_model.predict(val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz2jT1NGygJY",
        "outputId": "f962f203-b8cc-4a69-f3c5-b8c443125ba5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 5869s 79s/step\n",
            "31/31 [==============================] - 2458s 79s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_target = to_categorical(train.labels)\n",
        "val_target = to_categorical(val.labels)"
      ],
      "metadata": {
        "id": "PMnGjhLDZ5LB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build The VGG16 CNN Model**"
      ],
      "metadata": {
        "id": "oLWhUkTwYyXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(7,7,512)))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "blzYsLZrY3Vu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile The Model**"
      ],
      "metadata": {
        "id": "4zWVy5YaZQHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')"
      ],
      "metadata": {
        "id": "ZI4IrbQwZTWm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "8zgtM8AsZaqa",
        "outputId": "a3874801-2bac-4802-bba6-381177d42cb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               2508900   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 100)               400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2510310 (9.58 MB)\n",
            "Trainable params: 2510110 (9.58 MB)\n",
            "Non-trainable params: 200 (800.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train The Model**"
      ],
      "metadata": {
        "id": "5-vYQyn3ZdmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(vgg_features_train, train_target, epochs=50, batch_size=128, validation_data=(vgg_features_val, val_target))"
      ],
      "metadata": {
        "id": "Y-D_I0OqZiCn",
        "outputId": "327b125d-95db-42a1-9b9c-14d7d5dd7f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "74/74 [==============================] - 9s 111ms/step - loss: 0.4407 - accuracy: 0.8830 - val_loss: 0.2012 - val_accuracy: 0.9383\n",
            "Epoch 2/50\n",
            "74/74 [==============================] - 6s 77ms/step - loss: 0.1307 - accuracy: 0.9763 - val_loss: 0.1749 - val_accuracy: 0.9478\n",
            "Epoch 3/50\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 0.0595 - accuracy: 0.9936 - val_loss: 0.1724 - val_accuracy: 0.9485\n",
            "Epoch 4/50\n",
            "74/74 [==============================] - 6s 77ms/step - loss: 0.0343 - accuracy: 0.9974 - val_loss: 0.1674 - val_accuracy: 0.9470\n",
            "Epoch 5/50\n",
            "74/74 [==============================] - 7s 90ms/step - loss: 0.0224 - accuracy: 0.9985 - val_loss: 0.1713 - val_accuracy: 0.9434\n",
            "Epoch 6/50\n",
            "74/74 [==============================] - 6s 85ms/step - loss: 0.0154 - accuracy: 0.9990 - val_loss: 0.1681 - val_accuracy: 0.9473\n",
            "Epoch 7/50\n",
            "74/74 [==============================] - 10s 142ms/step - loss: 0.0130 - accuracy: 0.9996 - val_loss: 0.1734 - val_accuracy: 0.9475\n",
            "Epoch 8/50\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 0.0108 - accuracy: 0.9996 - val_loss: 0.1697 - val_accuracy: 0.9468\n",
            "Epoch 9/50\n",
            "74/74 [==============================] - 8s 106ms/step - loss: 0.0081 - accuracy: 0.9996 - val_loss: 0.1693 - val_accuracy: 0.9480\n",
            "Epoch 10/50\n",
            "74/74 [==============================] - 6s 75ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.1788 - val_accuracy: 0.9460\n",
            "Epoch 11/50\n",
            "74/74 [==============================] - 6s 88ms/step - loss: 0.0063 - accuracy: 0.9998 - val_loss: 0.1779 - val_accuracy: 0.9468\n",
            "Epoch 12/50\n",
            "74/74 [==============================] - 6s 76ms/step - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.1845 - val_accuracy: 0.9447\n",
            "Epoch 13/50\n",
            "74/74 [==============================] - 6s 83ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.1777 - val_accuracy: 0.9460\n",
            "Epoch 14/50\n",
            "74/74 [==============================] - 5s 71ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.1841 - val_accuracy: 0.9452\n",
            "Epoch 15/50\n",
            "74/74 [==============================] - 6s 76ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9445\n",
            "Epoch 16/50\n",
            "74/74 [==============================] - 6s 87ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.1942 - val_accuracy: 0.9424\n",
            "Epoch 17/50\n",
            "74/74 [==============================] - 6s 76ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.1970 - val_accuracy: 0.9424\n",
            "Epoch 18/50\n",
            "74/74 [==============================] - 7s 92ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.1956 - val_accuracy: 0.9465\n",
            "Epoch 19/50\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.1904 - val_accuracy: 0.9427\n",
            "Epoch 20/50\n",
            "74/74 [==============================] - 6s 77ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.1957 - val_accuracy: 0.9437\n",
            "Epoch 21/50\n",
            "74/74 [==============================] - 5s 70ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.1979 - val_accuracy: 0.9414\n",
            "Epoch 22/50\n",
            "74/74 [==============================] - 5s 65ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.2123 - val_accuracy: 0.9419\n",
            "Epoch 23/50\n",
            "74/74 [==============================] - 6s 79ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.2006 - val_accuracy: 0.9401\n",
            "Epoch 24/50\n",
            "74/74 [==============================] - 5s 66ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.2001 - val_accuracy: 0.9419\n",
            "Epoch 25/50\n",
            "74/74 [==============================] - 6s 87ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.2085 - val_accuracy: 0.9452\n",
            "Epoch 26/50\n",
            "74/74 [==============================] - 5s 74ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.2133 - val_accuracy: 0.9409\n",
            "Epoch 27/50\n",
            "74/74 [==============================] - 6s 79ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.2128 - val_accuracy: 0.9391\n",
            "Epoch 28/50\n",
            "74/74 [==============================] - 5s 70ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.2143 - val_accuracy: 0.9366\n",
            "Epoch 29/50\n",
            "74/74 [==============================] - 6s 79ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.2142 - val_accuracy: 0.9376\n",
            "Epoch 30/50\n",
            "74/74 [==============================] - 6s 77ms/step - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.2251 - val_accuracy: 0.9396\n",
            "Epoch 31/50\n",
            "74/74 [==============================] - 5s 70ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.2402 - val_accuracy: 0.9355\n",
            "Epoch 32/50\n",
            "74/74 [==============================] - 6s 83ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.2275 - val_accuracy: 0.9358\n",
            "Epoch 33/50\n",
            "74/74 [==============================] - 6s 79ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.2388 - val_accuracy: 0.9368\n",
            "Epoch 34/50\n",
            "74/74 [==============================] - 6s 82ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.2442 - val_accuracy: 0.9327\n",
            "Epoch 35/50\n",
            "74/74 [==============================] - 5s 69ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.2249 - val_accuracy: 0.9363\n",
            "Epoch 36/50\n",
            "74/74 [==============================] - 6s 87ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.2441 - val_accuracy: 0.9350\n",
            "Epoch 37/50\n",
            "74/74 [==============================] - 5s 71ms/step - loss: 0.0106 - accuracy: 0.9978 - val_loss: 0.2468 - val_accuracy: 0.9401\n",
            "Epoch 38/50\n",
            "74/74 [==============================] - 6s 75ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.2619 - val_accuracy: 0.9361\n",
            "Epoch 39/50\n",
            "74/74 [==============================] - 6s 77ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.2535 - val_accuracy: 0.9355\n",
            "Epoch 40/50\n",
            "74/74 [==============================] - 5s 70ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.2461 - val_accuracy: 0.9401\n",
            "Epoch 41/50\n",
            "74/74 [==============================] - 6s 84ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.2631 - val_accuracy: 0.9361\n",
            "Epoch 42/50\n",
            "74/74 [==============================] - 7s 97ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.2347 - val_accuracy: 0.9409\n",
            "Epoch 43/50\n",
            "74/74 [==============================] - 6s 83ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.2522 - val_accuracy: 0.9355\n",
            "Epoch 44/50\n",
            "74/74 [==============================] - 6s 79ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.2318 - val_accuracy: 0.9417\n",
            "Epoch 45/50\n",
            "74/74 [==============================] - 6s 85ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.2348 - val_accuracy: 0.9432\n",
            "Epoch 46/50\n",
            "74/74 [==============================] - 5s 70ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.2389 - val_accuracy: 0.9450\n",
            "Epoch 47/50\n",
            "74/74 [==============================] - 7s 90ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.2512 - val_accuracy: 0.9406\n",
            "Epoch 48/50\n",
            "74/74 [==============================] - 5s 72ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.2408 - val_accuracy: 0.9424\n",
            "Epoch 49/50\n",
            "74/74 [==============================] - 6s 84ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.2331 - val_accuracy: 0.9450\n",
            "Epoch 50/50\n",
            "74/74 [==============================] - 5s 70ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.2399 - val_accuracy: 0.9414\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d7aa6f3ad10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accurancy after 50 epochs is 99.93%, making the VGG16 architecture of this CNN model suitable for the ImageNet dataset."
      ],
      "metadata": {
        "id": "-jZdydDKbdbA"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}